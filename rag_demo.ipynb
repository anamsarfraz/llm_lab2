{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strategic plan covers the years 2024 to 2028.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from langfuse.llama_index import LlamaIndexCallbackHandler\n",
    " \n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "langfuse_callback_handler = LlamaIndexCallbackHandler()\n",
    "Settings.callback_manager = CallbackManager([langfuse_callback_handler])\n",
    "\n",
    "\n",
    "# Load documents from a directory (you can change this path as needed)\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "# Create an index from the documents\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Create a query engine\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Example query\n",
    "response = query_engine.query(\"What years does the strategic plan cover?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capstone project in the LLM Bootcamp focuses on two main ideas: a Health Assistant idea that involves building a personal assistant focused on health to assist users with health-related queries, monitor health trends, send reminders, and provide information or advice; and an Extended Functionality idea that aims to extend meeting summarization to longer events like conferences, including multiple speakers and presentations.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What ideas does the capstone project in the llm bootcamp focus on?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant documents: 2\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document 1:\n",
      "Text sample: CodePath\n",
      "2024-28\n",
      "Strategic\n",
      "Plan\n",
      "+\n",
      "Appendices\n",
      "(V1\n",
      "|\n",
      "04.23.24)\n",
      "Executive\n",
      "Summary\n",
      "Problem\n",
      "Solution\n",
      "Impact\n",
      "and\n",
      "Evidence\n",
      "To\n",
      "Date\n",
      "Introduction\n",
      "to\n",
      "the\n",
      "2024-28\n",
      "Plan\n",
      "Pillar\n",
      "1:\n",
      "Scale\n",
      "Nationally\n",
      "in\n",
      "Breadth,\n",
      "and\n",
      "...\n",
      "Metadata: {'page_label': '1', 'file_name': 'CodePath strategic plan.pdf', 'file_path': '/Users/usarfraz/extra_stuff/llm_bootcamp/lab2/data/CodePath strategic plan.pdf', 'file_type': 'application/pdf', 'file_size': 1452743, 'creation_date': '2024-09-16', 'last_modified_date': '2024-09-16'}\n",
      "Score: 0.8268825437512243\n",
      "\n",
      "==================================================\n",
      "\n",
      "Document 2:\n",
      "Text sample: corporate\n",
      "and\n",
      "college\n",
      "customers.\n",
      "Given\n",
      "that\n",
      "it\n",
      "takes\n",
      "time\n",
      "for\n",
      "sales\n",
      "personnel\n",
      "to\n",
      "ramp\n",
      "up,\n",
      "coupled\n",
      "with\n",
      "the\n",
      "six-\n",
      "to\n",
      "nine-month\n",
      "lead\n",
      "time\n",
      "required\n",
      "to\n",
      "close\n",
      "six-figure\n",
      "enterprise\n",
      "deals,\n",
      "this\n",
      "investment\n",
      "w...\n",
      "Metadata: {'page_label': '24', 'file_name': 'CodePath strategic plan.pdf', 'file_path': '/Users/usarfraz/extra_stuff/llm_bootcamp/lab2/data/CodePath strategic plan.pdf', 'file_type': 'application/pdf', 'file_size': 1452743, 'creation_date': '2024-09-16', 'last_modified_date': '2024-09-16'}\n",
      "Score: 0.809003303696042\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Create an index from the documents done above\n",
    "#index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Create a retriever to fetch relevant documents\n",
    "retriever = index.as_retriever(retrieval_mode='similarity', k=5)\n",
    "\n",
    "# Define your query\n",
    "query = \"What years does the strategic plan cover?\"\n",
    "\n",
    "# Retrieve relevant documents\n",
    "relevant_docs = retriever.retrieve(query)\n",
    "\n",
    "print(f\"Number of relevant documents: {len(relevant_docs)}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "for i, doc in enumerate(relevant_docs):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"Text sample: {doc.node.get_content()[:200]}...\")  # Print first 200 characters\n",
    "    print(f\"Metadata: {doc.node.metadata}\")\n",
    "    print(f\"Score: {doc.score}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strategic plan covers the years 2024 to 2028.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "    \n",
    "prompt = f\"\"\"\n",
    "    Given the following context, answer the question:\n",
    "    {relevant_docs}\n",
    "    Question: What years does the strategic plan cover?\n",
    "    \"\"\"\n",
    "    \n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse_callback_handler.flush()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
